# ============================================================
# CHATBOT PROJECT REQUIREMENTS
# Python Version: 3.12.10
# Last Updated: January 7, 2026
# Environment: chatbot-env
# ============================================================

# Core NLP Libraries
nltk==3.9.2
spacy==3.8.11
transformers==4.57.3
datasets==4.4.2
torch==2.9.1
torchvision==0.24.1
torchaudio==2.9.1
tokenizers==0.22.1
accelerate==1.12.0
# bitsandbytes==0.49.0

# Install PyTorch (latest stable):
# pip install torch torchvision torchaudio

# Traditional Chatbot Framework
python-aiml==0.9.3

# NOTE: ChatterBot excluded due to Python 3.11+ incompatibility
# ChatterBot==1.0.8  # EXCLUDED - Requires Python 3.7-3.8
# chatterbot-corpus==1.2.0  # EXCLUDED - ChatterBot dependency
# Alternative: Use python-aiml for rule-based approach

# Machine Learning
scikit-learn==1.8.0
scipy==1.16.3
scikit-image==0.26.0

# Data Processing & Analysis
pandas==2.3.3
numpy==2.3.5
pyarrow==22.0.0
pyyaml==6.0.2

# Visualization
matplotlib==3.10.8
seaborn==0.13.2
plotly==6.5.0

# Explainability & Interpretation
lime==0.2.0.1
shap==0.50.0

# Evaluation Metrics
rouge-score==0.1.2

# Jupyter & Interactive Development
jupyter==1.1.1
notebook==7.5.1
jupyterlab==4.5.1
ipywidgets==8.1.8
ipykernel==7.1.0

# NLP Models & Embeddings
sentence-transformers==5.2.0
gensim==4.4.0
huggingface-hub==0.36.0

# Google Gemini API
google-genai>=1.0.0

# Utilities
tqdm==4.67.1
requests==2.32.5

# Database (MongoDB)
pymongo==4.15.5
motor==3.7.1

# Vector Database (Qdrant) - for RAG
qdrant-client>=1.9.0

google-generativeai

# Configuration Management (12-Factor App)
pydantic-settings==2.12.0
pydantic==2.12.5
python-dotenv==1.2.1

# Deep Learning Support
numba==0.63.0b1
networkx==3.6.1

# Testing & Quality
pytest==9.0.2
pytest-cov==7.0.0
pytest-mock==3.15.1
coverage==7.13.1

# Syntax Highlighting (for LaTeX/Paper)
pygments==2.19.2

# ============================================================
# ADDITIONAL DEPENDENCIES (automatically installed)
# ============================================================
# The following are installed automatically as dependencies
# of the packages above. Listed here for reference:
#
# - pydantic (for transformers)
# - safetensors (for model serialization)
# - tokenizers (for transformers)
# - joblib (for scikit-learn)
# - threadpoolctl (for parallel processing)
# - cloudpickle (for multiprocessing)
# - and many others...
#
# Run: pip freeze > requirements_full.txt
# for complete list with exact versions
# ============================================================

# ============================================================
# NLTK DATA PACKAGES (install separately after requirements)
# ============================================================
# Run these commands to download required NLTK data:
#
# python -c "import nltk; nltk.download('punkt')"
# python -c "import nltk; nltk.download('punkt_tab')"
# python -c "import nltk; nltk.download('stopwords')"
# python -c "import nltk; nltk.download('wordnet')"
# python -c "import nltk; nltk.download('omw-1.4')"
# python -c "import nltk; nltk.download('averaged_perceptron_tagger')"
# python -c "import nltk; nltk.download('maxent_ne_chunker')"
# python -c "import nltk; nltk.download('words')"
#
# Or download all at once (takes longer):
# python -c "import nltk; nltk.download('all')"
# ============================================================

# ============================================================
# SPACY MODEL (install separately after requirements)
# ============================================================
# python -m spacy download en_core_web_sm
# ============================================================
