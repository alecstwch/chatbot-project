# General Info & Grading for NLP

### Z˘avelc˘a Miruna-Andreea

#### 2024

# General Info

Projects should be made in teams of 2-4 people. You can choose your subject from [here,](https://docs.google.com/document/d/1uBJpTmZj2-XCleRw6kTq9RXCAo6qGtbANhOizaf1kI8/edit?usp=sharing) but maximum 4 teams can chose the same subject. The only exception is the shared task, which can be chosen by an unlimited number of teams.

The project should have:

- paper / technical report following the classical structure of a research article
- implementation (code)
- slideshow presentation

And it should be focused on one of the following:

- the paper a survey describing the current state of the art (SOTA), existing methods with a comparison between them and an implementation from these methods tested both on the original dataset (if available) and on a different one.
- the implementation the paper will describe the problem at hand, chosen methodology and technical and experimental details for the tested approaches. The code will contain an end-to-end "application" able to solve the problem, using both classic as well as novel approaches.

Only one member from a team has to upload the project, but make sure all your names are visible on the paper and on the slideshow presentation. The project will be presented before the end of the semester. You can register your team [here](https://docs.google.com/spreadsheets/d/14aknyS5iol-CCXN2nQ82IBTCKtT25ItBk0Ao67qN1J4/edit?usp=sharing) (where you will also pick a timeslot for your presentation at the end of the semester).

#### Re-examinations and grade increases

The requirements remain the same, but you will work alone and the evaluation will be harsher.

# Grading

### Project

For full marks it is mandatory to have a complete, non-plagiarized project, with Latex documentation and relevant references. What we will look for:

- Explaining your motivation and what problems could be solved by your project
- Data Analysis: graphics, what you expected from your observations vs. what actually happened
- Comparison between the preprocessing methods you chose in your project / justification if you only chose one ("it worked well" does not count as competent justification)
- Comparison / justifications for your embeddings
- Comparison between multiple models
- Hyperparameter tunning or justification if it does not exist
- Training on at least 1 traditional model, 1 neural network and 1 transformer
- Justification for the neural network / transformer architecture
- Justified non-trivial use of an LLM
- Testing your model / approach on multiple datasets
- Explainability
- Error analysis
- Originality (subject / implementation)
- Overall quality of your work

It is not expected to solve all bullets. Choose what works best for your project and try to make the best out of it. Observe and discuss what works, what doesn't and why that happens.