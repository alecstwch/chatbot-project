{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEuuzNUQ_MSG"
      },
      "source": [
        "# Word Representations (Embeddings)\n",
        "\n",
        "In natural language processing, word embedding is the term used for representing a word as a vector. For training a model we need numerical data, which means that we must find a way to represent texts such that we keep as much information as possible considering our current context. This means that sometimes semantic relations will be more important, other times lexical information etc.\n",
        "\n",
        "By using word embeddings (vectorization) we can represent each word as a number or a list of numbers that conveys this information such that words that are similar will be closer to each other in the vector space than words that are not.\n",
        "\n",
        "[A nice illustration](https://jalammar.github.io/illustrated-word2vec/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUqzZuWWhUuw"
      },
      "source": [
        "# Bag of Words (BoW)\n",
        "\n",
        "Imagine a situation where the context of the words is not relevant, only how often they appear. This is where we use bag of words. This approach just throws all words in a bag, maybe shuffles it a bit, then counts how many times each words appears (or if they appear in case of a binary BoW). It is the easiest vectorization method that we will discuss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS2s198nbhgT"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?export=view&id=1v6McR199QkVXvuQmC3FWJ80rSXGTbZUS' width=500></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AExe5lbiUNm"
      },
      "source": [
        "Let's take the text from the example. We can either write our own BoW implementation, or we can use the one preimplemented in [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymHBxvsQiKXV",
        "outputId": "31f8c0fe-ec94-4286-e82c-ba2a24217bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['did' 'fly' 'see' 'the' 'will' 'with' 'you']\n",
            "[[1 1 1 1 0 0 1]\n",
            " [0 2 0 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = ['Did you see the fly?', 'The fly will fly with you.']\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(text)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGKVdy4-sgoy"
      },
      "source": [
        "CountVectorizer is a class with predefined parameters. You can always change those parameters, meaning that you can, for example, choose to have a binary representation of bigrams:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n3BFJtLpb2H",
        "outputId": "223bcc80-aac6-4250-a68c-bd2f856b2604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['am not' 'he is' 'is very' 'not happy' 'very happy']\n",
            "[[1 0 0 1 0]\n",
            " [0 1 1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "text = ['I am not happy.', 'He is very happy']\n",
        "vectorizer = CountVectorizer(binary=True, ngram_range=(2, 2))\n",
        "X = vectorizer.fit_transform(text)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThLRQJI3uLyc"
      },
      "source": [
        "N-grams are sequences of n words. They help us get some context about the text, letting us know the difference between _not happy_ and _very happy_ for example. This can be used as a feature for another representation, or on its own to make assumptions about the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLcyp5Ed6QKT"
      },
      "source": [
        "#  Term Frequency - Inverse Document Frequency (Tf-idf)\n",
        "\n",
        "Just because a word appears often it does not mean that it is necessarily relevant (think about stopwords). If we want to write a search engine for example, it would be more relevant for us to know how often a certain word appears in a document with regards to how common that word generally is. Tf-idf is an algorithm that takes this into account. In other words, a word is important for a given document if it appears many times in this one and rarely in others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaNvpl8r1teo"
      },
      "source": [
        "We will consider the given document as the current datapoint and repeat the following for each word in the dataset:\n",
        "$$TFIDF = TF * IDF$$\n",
        "where:\n",
        "$$TF(word, document) = \\frac{How\\ many\\ times\\ the\\ word\\ appears\\ in\\ the\\ document}{Number\\ of\\ words\\ in\\ the\\ document}$$\n",
        "and:\n",
        "$$IDF(word, Documents) = log(\\frac{Number\\ of\\ documents\\ in\\ the\\ corpus}{How\\ many\\ documents\\ contain\\ the\\ current\\ word} + 1)$$\n",
        "We use **log** in order to smooth our values for an easier analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDamrGeM6H5I"
      },
      "source": [
        "For the implementation you can use [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). The output will be a matrix where each row corresponds to a datapoint and each column to a word from the full dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA5hy4bW4d78",
        "outputId": "8155320d-476e-4dc6-d653-99a620cadc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['am' 'happy' 'he' 'is' 'not' 'very']\n",
            "[[0.6316672  0.44943642 0.         0.         0.6316672  0.        ]\n",
            " [0.         0.37997836 0.53404633 0.53404633 0.         0.53404633]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "text = ['I am not happy.', 'He is very happy']\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(text)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "688u3vTnBmbe"
      },
      "source": [
        "# Word2vec\n",
        "\n",
        "Word2vec was one the most popular embedding technique used before the rise of the Transformer in [2017](https://arxiv.org/pdf/1706.03762.pdf). It was originaly published in 2013 ([\\[1\\]](https://arxiv.org/pdf/1310.4546.pdf), [\\[2\\]](https://arxiv.org/pdf/1310.4546.pdf)) and it consists of a shallow neural network (with only one hidden layer) trained on each word from a text independently such that similar words are closer to eachother in the vector space (and unrelated words are further).\n",
        "\n",
        "It all starts from the quote: _You shall know a word by the company it keeps_. The idea is that we can use the context of a word to compute the similarity between different words in our text, use this as a training dataset and create a prediction model that works as an embedding for the words we have in our corpus. The model can use one of the following algorithms:\n",
        "- Continuous Bag of Words (CBoW): use the context window around a word to predict the word; better for small datasets\n",
        "- Skip-Gram: use a target word to predict the context around it; better at generalization (for rare words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2A-MW5l8VNw"
      },
      "source": [
        "<img src= \"https://wiki.pathmind.com/images/wiki/word2vec_diagrams.png\" width=\"500\" height=\"300\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpgWJMSYZscX"
      },
      "source": [
        "[A more in depth explanation with code](https://www.tensorflow.org/text/tutorials/word2vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beiDzdTpwdu9"
      },
      "source": [
        "## Continuous Bag-of-Words (CBoW)\n",
        "\n",
        "Unlike the BoW model, CBoW takes into account the context around a certain word by using a context window.\n",
        "\n",
        "\n",
        "For example, if you choose the text _The fly will fly with you._ and the window size 1, it will look at exactly 1 word before and after each word in the text, generating the following sequence of (_context_, _target_) pairs:\n",
        "\n",
        "$$([the, will], fly), ([fly, fly], will), ([will, with], fly), ([fly, you], with)$$\n",
        "\n",
        "This is the information on which we will train our model to predict the most probable word in a given context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-GATH4E_TxQ"
      },
      "source": [
        "## Skip-Gram\n",
        "\n",
        "The Skip-Gram Model works the other way around: given a target word, it aims to predict the context around it. In order to do this, you can train a neural network with one hidden layer for a simple task: to predict the chance of having word _y_ really close to word _x_ in a random text. Then you use this layer as the vector representation of the given word, thus making sure that the vector distance between any 2 words is closer if they are more similar and larger if they are not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPpWQth08oc-"
      },
      "source": [
        "## Training a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3t7lt-M8q3Z"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "embedding = Word2Vec(\n",
        "    sentences=common_texts,   # the list of sentences, where each sentence is given as a list of words (processed or not processed)\n",
        "    vector_size=100,          # the number of features in the vectorized representation\n",
        "    window=7,                 # the context window\n",
        "    min_count=3,              # the minimum number of times a word should appear in our dataset in order to be counted\n",
        "    sg=1                      # sg=1 means skip-gram is used, sg=0 means CBOW is used\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-fzorLDPWjg",
        "outputId": "96211085-b230-48db-88ad-530759fa4ed7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'system': 0, 'graph': 1, 'trees': 2, 'user': 3}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding.wv.key_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "Kl1WqhlUPfLC",
        "outputId": "1cc51037-968c-46ad-d8fa-4f327af5fb86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89338bf3-44f0-4f02-a44e-4367b790eb1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>system</th>\n",
              "      <td>-0.000536</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.009009</td>\n",
              "      <td>-0.009303</td>\n",
              "      <td>-0.007117</td>\n",
              "      <td>0.006459</td>\n",
              "      <td>0.008973</td>\n",
              "      <td>-0.005015</td>\n",
              "      <td>-0.003763</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.003474</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.009619</td>\n",
              "      <td>0.005061</td>\n",
              "      <td>-0.008917</td>\n",
              "      <td>-0.007042</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>0.006393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>graph</th>\n",
              "      <td>-0.008620</td>\n",
              "      <td>0.003666</td>\n",
              "      <td>0.005190</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.007467</td>\n",
              "      <td>-0.006168</td>\n",
              "      <td>0.001106</td>\n",
              "      <td>0.006047</td>\n",
              "      <td>-0.002840</td>\n",
              "      <td>-0.006174</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>-0.001576</td>\n",
              "      <td>0.002197</td>\n",
              "      <td>-0.007882</td>\n",
              "      <td>-0.002717</td>\n",
              "      <td>0.002663</td>\n",
              "      <td>0.005347</td>\n",
              "      <td>-0.002392</td>\n",
              "      <td>-0.009510</td>\n",
              "      <td>0.004506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trees</th>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.003077</td>\n",
              "      <td>-0.006813</td>\n",
              "      <td>-0.001375</td>\n",
              "      <td>0.007669</td>\n",
              "      <td>0.007346</td>\n",
              "      <td>-0.003673</td>\n",
              "      <td>0.002643</td>\n",
              "      <td>-0.008317</td>\n",
              "      <td>0.006205</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004509</td>\n",
              "      <td>0.005702</td>\n",
              "      <td>0.009180</td>\n",
              "      <td>-0.004100</td>\n",
              "      <td>0.007965</td>\n",
              "      <td>0.005375</td>\n",
              "      <td>0.005879</td>\n",
              "      <td>0.000513</td>\n",
              "      <td>0.008213</td>\n",
              "      <td>-0.007019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user</th>\n",
              "      <td>-0.008243</td>\n",
              "      <td>0.009299</td>\n",
              "      <td>-0.000198</td>\n",
              "      <td>-0.001967</td>\n",
              "      <td>0.004604</td>\n",
              "      <td>-0.004095</td>\n",
              "      <td>0.002743</td>\n",
              "      <td>0.006940</td>\n",
              "      <td>0.006065</td>\n",
              "      <td>-0.007511</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007426</td>\n",
              "      <td>-0.001064</td>\n",
              "      <td>-0.000795</td>\n",
              "      <td>-0.002563</td>\n",
              "      <td>0.009683</td>\n",
              "      <td>-0.000459</td>\n",
              "      <td>0.005874</td>\n",
              "      <td>-0.007448</td>\n",
              "      <td>-0.002506</td>\n",
              "      <td>-0.005550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows Ã— 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89338bf3-44f0-4f02-a44e-4367b790eb1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89338bf3-44f0-4f02-a44e-4367b790eb1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89338bf3-44f0-4f02-a44e-4367b790eb1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15324094-164e-4cf5-b645-4b24705944fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15324094-164e-4cf5-b645-4b24705944fd')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15324094-164e-4cf5-b645-4b24705944fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              0         1         2         3         4         5         6   \\\n",
              "system -0.000536  0.000236  0.005103  0.009009 -0.009303 -0.007117  0.006459   \n",
              "graph  -0.008620  0.003666  0.005190  0.005742  0.007467 -0.006168  0.001106   \n",
              "trees   0.000095  0.003077 -0.006813 -0.001375  0.007669  0.007346 -0.003673   \n",
              "user   -0.008243  0.009299 -0.000198 -0.001967  0.004604 -0.004095  0.002743   \n",
              "\n",
              "              7         8         9   ...        90        91        92  \\\n",
              "system  0.008973 -0.005015 -0.003763  ...  0.001631  0.000190  0.003474   \n",
              "graph   0.006047 -0.002840 -0.006174  ...  0.001088 -0.001576  0.002197   \n",
              "trees   0.002643 -0.008317  0.006205  ... -0.004509  0.005702  0.009180   \n",
              "user    0.006940  0.006065 -0.007511  ... -0.007426 -0.001064 -0.000795   \n",
              "\n",
              "              93        94        95        96        97        98        99  \n",
              "system  0.000218  0.009619  0.005061 -0.008917 -0.007042  0.000901  0.006393  \n",
              "graph  -0.007882 -0.002717  0.002663  0.005347 -0.002392 -0.009510  0.004506  \n",
              "trees  -0.004100  0.007965  0.005375  0.005879  0.000513  0.008213 -0.007019  \n",
              "user   -0.002563  0.009683 -0.000459  0.005874 -0.007448 -0.002506 -0.005550  \n",
              "\n",
              "[4 rows x 100 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    [embedding.wv.get_vector(word) for word in embedding.wv.key_to_index.keys()],\n",
        "    index=embedding.wv.key_to_index\n",
        "  )\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzOAPvYRRBh3",
        "outputId": "e719dac7-cf2c-40c1-cb86-e5bdefdc6e84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('graph', -0.01083916611969471),\n",
              " ('trees', -0.05234673246741295),\n",
              " ('user', -0.111670583486557)]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding.wv.most_similar('system')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDvBrIhFOC4c"
      },
      "source": [
        "## Loading a pretrained model\n",
        "\n",
        "[Info about data and models](https://github.com/piskvorky/gensim-data)\n",
        "\n",
        "[Examples on how to use](https://radimrehurek.com/gensim/models/word2vec.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgUfTBUF9jhA"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "api.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7RvuW6GWujS",
        "outputId": "dec83c65-c1d9-467c-c884-ee1e20832214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[=================---------------------------------] 35.9% 597.3/1662.8MB downloaded"
          ]
        }
      ],
      "source": [
        "model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2TYOua6XTCm",
        "outputId": "d12e4c50-71e2-4f24-8f7b-67d3add58020"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('systems', 0.7227916717529297),\n",
              " ('sytem', 0.7129376530647278),\n",
              " ('sys_tem', 0.5871982574462891),\n",
              " ('System', 0.5275423526763916),\n",
              " ('mechanism', 0.5058810114860535),\n",
              " ('sysem', 0.5027822852134705),\n",
              " ('systen', 0.49969804286956787),\n",
              " ('system.The', 0.49599188566207886),\n",
              " ('sytems', 0.4949610233306885),\n",
              " ('computerized', 0.47604817152023315)]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar('system')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wARMjmwkXYKL",
        "outputId": "7d009206-3ddd-4556-8439-78b3a6c8f192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09396098"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity('system', 'graph')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxWxZU_qX19W"
      },
      "source": [
        "## Fine-tuning our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7SFjytpX46K"
      },
      "outputs": [],
      "source": [
        "model.train(common_texts, total_examples=4, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNpakyqBa_oK"
      },
      "source": [
        "Other cool stuff:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJ6FtC0bB1H",
        "outputId": "e19d9f2e-85b2-429b-b05a-a22712159dd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519),\n",
              " ('monarch', 0.6189674139022827),\n",
              " ('princess', 0.5902431011199951),\n",
              " ('crown_prince', 0.5499460697174072),\n",
              " ('prince', 0.5377321839332581),\n",
              " ('kings', 0.5236844420433044),\n",
              " ('Queen_Consort', 0.5235945582389832),\n",
              " ('queens', 0.5181134343147278),\n",
              " ('sultan', 0.5098593831062317),\n",
              " ('monarchy', 0.5087411999702454)]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1dZJXZ3bLwb"
      },
      "source": [
        "[And less cool stuff:](https://arxiv.org/pdf/1607.06520.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iPhuPiVbNUj",
        "outputId": "26be2301-0515-413d-cc4f-2a2ea721462b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('homemaker', 0.5627118945121765),\n",
              " ('housewife', 0.5105047225952148),\n",
              " ('graphic_designer', 0.505180299282074),\n",
              " ('schoolteacher', 0.497949481010437),\n",
              " ('businesswoman', 0.493489146232605),\n",
              " ('paralegal', 0.49255111813545227),\n",
              " ('registered_nurse', 0.4907974898815155),\n",
              " ('saleswoman', 0.4881627559661865),\n",
              " ('electrical_engineer', 0.4797725975513458),\n",
              " ('mechanical_engineer', 0.4755399227142334)]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar(positive=[\"computer_programmer\", \"woman\"], negative=[\"man\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_dqRxhjbnT_"
      },
      "source": [
        "Bias is still an unsolved problem in Machine Learning. Do you know any other popular examples of bias?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiHaJDLOgYnp"
      },
      "source": [
        "# Global Vectors (GloVe)\n",
        "\n",
        "While Word2Vec is based only on local statistics (the occurence of words at\n",
        "a single-sentence level) [GloVe](https://nlp.stanford.edu/projects/glove/) incorporates global statistics methods. This makes it better suited for smaller datasets, as it does not need as much training data.\n",
        "\n",
        "The model counts all \"word1 word2 ...\" pairs (for a context window of x we consider words that have at most distance x between them) and keeps the information in a co-occurrence matrix:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ7WU2agz4b2"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?export=view&id=1pnX1lPdQItUauHp9W8xJlx8q2lgTe4cJ' width=500></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Y4Noij2Egg"
      },
      "source": [
        "Afterwards, it computes the probability that a word will be closer to another one based on this matrix:\n",
        "$$P(j | i) = \\frac{X_{ij}}{X_i}$$\n",
        "where:\n",
        "$$P(j | i) = the\\ probability\\ of\\ word\\ j\\ given\\ i$$\n",
        "$$X_{ij} = how\\ many\\ times\\ word\\ j\\ appears\\ in\\ the\\ context\\ of\\ i$$\n",
        "$$X_i = \\sum_k X_{ik} = sum\\ of\\ how\\ many\\ times\\ words\\ appear\\ in\\ the\\ context\\ of\\ i$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg2yYtcC_TIJ"
      },
      "source": [
        "Based on this we should be able to infer relations between words:\n",
        "\n",
        "<center><img src='https://nlp.stanford.edu/projects/glove/images/table.png' width=500></center>\n",
        "\n",
        "Notice how _solid_ is related to _ice_ but not _steam_, while _gas_ is related to _steam_ but not _ice_ (very large vs. very small conditional values). _Water_ and _fashion_ on the other hand are either highly related to both or completely unrelated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW_-byU0Ad53"
      },
      "source": [
        "Some more computation will bring us to the regression model that is now used for this model. If you want to learn more you can check [the paper](https://aclanthology.org/D14-1162.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFdqo-FRQ7gP"
      },
      "source": [
        "## Using GloVe\n",
        "\n",
        "We can load a pretrained GloVe model using the gensim library (or other resources):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mY_dP3FQ6_n",
        "outputId": "7db963e5-d07a-426a-a131-2ffbfdc9e46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"glove-twitter-100\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUKW1ADEVX5d"
      },
      "source": [
        "And use it to compute the word embeddings (or do all other similarity functions that we saw for Word2Vec):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6ZEmJuKR9S9",
        "outputId": "e937c2a9-78d0-46aa-ea3a-245a9f827a21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.43887 ,  0.32601 , -0.28524 , -0.08248 ,  0.43643 ,  0.75065 ,\n",
              "        0.093945, -0.72626 ,  0.32297 , -0.37128 , -0.23306 ,  0.35499 ,\n",
              "       -3.1764  ,  0.015004,  0.69725 , -0.15256 ,  0.025449, -0.058944,\n",
              "        0.20002 , -0.61298 , -0.79661 ,  0.53051 ,  0.64765 ,  0.90153 ,\n",
              "       -0.27407 ,  0.52871 ,  0.39344 ,  0.56076 ,  0.31942 ,  0.83347 ,\n",
              "       -0.53268 , -1.0166  , -0.25328 , -0.17347 ,  0.68794 ,  0.25902 ,\n",
              "        0.42864 ,  0.3844  , -0.071415, -0.026013, -0.42733 ,  0.58874 ,\n",
              "       -0.30061 , -0.18357 ,  0.21158 , -0.72648 , -0.48477 ,  0.43527 ,\n",
              "       -0.37412 , -0.48493 ,  0.26264 ,  0.21684 , -0.8822  ,  0.57925 ,\n",
              "       -0.54    ,  0.7147  , -0.33133 , -0.44715 , -0.40713 , -0.014364,\n",
              "       -0.083808,  0.45569 , -0.094374,  0.56057 ,  0.65446 , -0.45768 ,\n",
              "        0.2522  ,  0.34328 , -0.061001, -0.4899  ,  0.3342  ,  0.41277 ,\n",
              "       -0.55403 ,  0.30807 ,  0.22867 , -0.53921 ,  0.16439 ,  0.021561,\n",
              "        0.15131 , -0.70287 ,  1.4152  ,  0.83387 ,  0.44385 , -0.042976,\n",
              "        0.069162, -0.74432 , -0.032278, -0.6221  ,  0.20007 ,  0.15834 ,\n",
              "       -0.53907 , -0.31442 ,  0.60969 , -0.32378 ,  0.1676  , -0.94943 ,\n",
              "        0.52916 ,  0.035842, -0.041395, -0.56533 ], dtype=float32)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model['system']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc22faRVaCpg"
      },
      "source": [
        "Or you can train your own model from scratch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG2UypDfaTjG"
      },
      "outputs": [],
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "corpus = Corpus()\n",
        "corpus.fit(common_texts, window=4)\n",
        "\n",
        "glove = Glove(no_components=4, learning_rate=0.1)\n",
        "glove.fit(corpus.matrix, epochs=10, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PI1K_gFayXI"
      },
      "source": [
        "# FastText\n",
        "\n",
        "The last embedding technique that we will talk about is FastText. With a really nice documentation, FastText also uses Skip-Gram and CBoW (like Word2Vec), but instead of learning words as a whole, it splits them in sequences of characters. This helps the model generalize better, especially with rare words, as it learns prefixes and suffixes along with other short sequences that convey information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Ui6YNbeAsX"
      },
      "source": [
        "If we choose to split the word _artificial_ in n-grams of size 3 and padding 1, the representation will be: <_ar_, _art_, _rti_, _tif_, _ifi_, _fic_, _ici_, _ial_, _al_>. And then we continue similar as with word2vec. The full explanation is in [the paper](https://aclanthology.org/E17-2068.pdf) and code snippets are in the [documentation](https://fasttext.cc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55UuO7SZRcJs"
      },
      "source": [
        "# Principal Component Analysis (PCA)\n",
        "\n",
        "PCA is a dimensionality reduction algorithm -- meaning that we can use it to visualise our data in 2D or 3D. Here is an example of how you can use it to see the distance between embeddings in 2D:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSYbiUpQMaM-"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "text = ['system', 'graph', 'trees', 'user']\n",
        "embeddings = [model[word] for word in text]\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(embeddings)\n",
        "vectors_2d = pca.transform(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can train it the same way we would a normal ML model, and visualize the results using, for example, a plotting library like matplotlib:"
      ],
      "metadata": {
        "id": "K3OgyZ5CB4Wh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxhT5BnPQZXI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [v[0] for v in vectors_2d]\n",
        "y = [v[1] for v in vectors_2d]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x, y)\n",
        "\n",
        "for i, txt in enumerate(text):\n",
        "    ax.annotate(txt, (x[i], y[i]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "\n",
        "1. Write your own implementation for Bag of Words from scratch. You should be able to set whether the representation will be binary or frequency-based.\n",
        "2. Implement your own TfIdf from scratch. You can use as many helper functions as you want.\n",
        "3. Create the (context, target) pairs and train a neural network for either skip-gram or continuous bag of words. You should quantify each word with a unique id and use padding at the beginning and end of the text for training on the marginal terms.\n",
        "4. Visualise the distance between a few words in 2D using PCA (or another dimensionality reduction technique)\n",
        "5. Compare these embeddings using any means (e.g.: train time, most similar word to X, distances in a 2D space, accuracy with a SVM etc.). Also compare the library versions with your own implementations.\n"
      ],
      "metadata": {
        "id": "h1gAEDfAnkoG"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sUqzZuWWhUuw",
        "yLcyp5Ed6QKT",
        "688u3vTnBmbe",
        "hPpWQth08oc-",
        "TDvBrIhFOC4c",
        "JxWxZU_qX19W",
        "TiHaJDLOgYnp",
        "cFdqo-FRQ7gP",
        "6PI1K_gFayXI"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}